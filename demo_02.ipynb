{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T05:22:44.171489Z",
     "start_time": "2021-01-17T05:22:44.167018Z"
    }
   },
   "outputs": [],
   "source": [
    "import librosa # 音频处理库\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,LSTM,TimeDistributed,Bidirectional\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, log_loss\n",
    "# 分层采样的K折交叉 确保训练集，测试集中各类别样本的比例与原始数据集中相同\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T05:22:44.188503Z",
     "start_time": "2021-01-17T05:22:44.173003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\14595\\\\Desktop\\\\baby婴儿啼哭识别'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_base = os.getcwd()\n",
    "dir_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T05:27:13.042460Z",
     "start_time": "2021-01-17T05:27:13.028497Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = r'C:\\Users\\14595\\Desktop\\baby婴儿啼哭识别\\train\\\\'\n",
    "\n",
    "def get_labels(path=DATA_PATH):\n",
    "    labels = os.listdir(path)\n",
    "    print(labels)\n",
    "    label_indices = np.arange(0, len(labels)) # 返回[0,1,....len(labels)]步长队列\n",
    "    return labels, label_indices, to_categorical(label_indices) # 标签， 标签index， index独热编码\n",
    "\n",
    "def more_feat(wave, sr):\n",
    "    a = librosa.feature.zero_crossing_rate(wave,sr)\n",
    "    b = librosa.feature.spectral_centroid(wave,sr=sr)[0]\n",
    "    a = np.vstack((a,b))\n",
    "    b = librosa.feature.chroma_stft(wave,sr)\n",
    "#     a = np.vstack((a,b))\n",
    "#     b = librosa.feature.spectral_contrast(wave,sr)\n",
    "    a = np.vstack((a,b))\n",
    "    b = librosa.feature.spectral_bandwidth(wave,sr)\n",
    "#     a = np.vstack((a,b))\n",
    "#     b = librosa.feature.tonnetz(wave,sr)\n",
    "    a = np.vstack((a,b))\n",
    "    return a\n",
    "\n",
    "def save_data_to_array(path=DATA_PATH):\n",
    "    labels, _, _ = get_labels(path)\n",
    "\n",
    "    for label in labels:\n",
    "        # 对每一种标签\n",
    "        mfcc_vectors = [] # mfcc向量\n",
    "        \n",
    "        wavfiles = [path + label + '\\\\' + wavfile for wavfile in os.listdir(path + '\\\\' + label)]\n",
    "        for wavfile in tqdm(wavfiles, \"Saving vectors of label - '{}'\".format(label)):\n",
    "            # 对每个音频文件\n",
    "            mfcc = np.zeros((40, 704))\n",
    "            wave, sr = librosa.load(wavfile, mono=True, sr=None)\n",
    "            if wave.shape[0] < 360000:\n",
    "                wave = np.pad(wave,(0,360000-wave.shape[0]),'constant')\n",
    "            wave = wave[:360000]\n",
    "            mfcc_re = librosa.feature.mfcc(wave, sr=8000, n_mfcc=40)\n",
    "            # (40,704)\n",
    "            mfcc = sklearn.preprocessing.scale(mfcc_re,axis=1)\n",
    "            # 更多特征\n",
    "            a = more_feat(wave, sr)\n",
    "            norm_a = sklearn.preprocessing.scale(a,axis=1)\n",
    "            norm_a = np.concatenate((norm_a,mfcc))\n",
    "            mfcc_vectors.append(norm_a)\n",
    "            \n",
    "        mfcc_vectors = np.stack(mfcc_vectors)\n",
    "        \n",
    "        np.save(label + '.npy', mfcc_vectors)\n",
    "        \n",
    "DATA_TEST_PATH = r'C:\\Users\\14595\\Desktop\\baby婴儿啼哭识别\\test'\n",
    "def save_data_to_array_test(path=DATA_TEST_PATH):\n",
    "    mfcc_vectors = []\n",
    "        \n",
    "    wavfiles = [DATA_TEST_PATH + '\\\\' + wavfile for wavfile in os.listdir(DATA_TEST_PATH)]\n",
    "    for wavfile in tqdm(wavfiles, \"Saving vectors of label - '{}'\".format('test')):\n",
    "        mfcc = np.zeros((40, 704))\n",
    "        wave, sr = librosa.load(wavfile, mono=True, sr=None)\n",
    "        if wave.shape[0] < 360000:\n",
    "            wave = np.pad(wave,(0,360000-wave.shape[0]),'constant')\n",
    "        wave = wave[:360000]\n",
    "        mfcc_re = librosa.feature.mfcc(wave, sr=8000, n_mfcc=40)\n",
    "        # (40,704)\n",
    "        mfcc = sklearn.preprocessing.scale(mfcc_re,axis=1)\n",
    "        # 更多特征\n",
    "        a = more_feat(wave, sr)\n",
    "        norm_a = sklearn.preprocessing.scale(a,axis=1)\n",
    "        norm_a = np.concatenate((norm_a,mfcc))\n",
    "        mfcc_vectors.append(norm_a)\n",
    "            \n",
    "    mfcc_vectors = np.stack(mfcc_vectors)\n",
    "    np.save('test.npy', mfcc_vectors)\n",
    "        \n",
    "\n",
    "def get_train_test(split_ratio=0.8, random_state=42):\n",
    "    labels, indices, _ = get_labels(DATA_PATH)\n",
    "\n",
    "\n",
    "    X = np.load(labels[0] + '.npy')\n",
    "    y = np.zeros(X.shape[0])\n",
    "\n",
    "    for i, label in enumerate(labels[1:]):\n",
    "        x = np.load(label + '.npy')\n",
    "        X = np.vstack((X, x))\n",
    "        y = np.append(y, np.full(x.shape[0], fill_value= (i + 1)))\n",
    "        # y添加一组x.shape[0]大小的值为i + 1的数据\n",
    "        # 标签\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T05:36:44.513580Z",
     "start_time": "2021-01-17T05:36:44.504636Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, (3, 3), activation='relu',input_shape = (55,704,1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.25)) \n",
    "    model.add(Convolution2D(32, (3, 3),  activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "    model.compile(optimizer='Adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T05:35:41.096016Z",
     "start_time": "2021-01-17T05:27:43.427198Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Saving vectors of label - 'awake':   0%|                                                       | 0/160 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['awake', 'diaper', 'hug', 'hungry', 'sleepy', 'uncomfortable']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving vectors of label - 'awake': 100%|█████████████████████████████████████████████| 160/160 [00:58<00:00,  2.73it/s]\n",
      "Saving vectors of label - 'diaper': 100%|████████████████████████████████████████████| 134/134 [00:57<00:00,  2.33it/s]\n",
      "Saving vectors of label - 'hug': 100%|███████████████████████████████████████████████| 160/160 [01:01<00:00,  2.61it/s]\n",
      "Saving vectors of label - 'hungry': 100%|████████████████████████████████████████████| 160/160 [00:58<00:00,  2.72it/s]\n",
      "Saving vectors of label - 'sleepy': 100%|████████████████████████████████████████████| 144/144 [00:56<00:00,  2.53it/s]\n",
      "Saving vectors of label - 'uncomfortable': 100%|█████████████████████████████████████| 160/160 [01:27<00:00,  1.83it/s]\n",
      "Saving vectors of label - 'test': 100%|██████████████████████████████████████████████| 228/228 [01:36<00:00,  2.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# save_data_to_array()\n",
    "# save_data_to_array_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T05:36:02.140539Z",
     "start_time": "2021-01-17T05:36:01.343637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['awake', 'diaper', 'hug', 'hungry', 'sleepy', 'uncomfortable']\n"
     ]
    }
   ],
   "source": [
    "X, Y = get_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T05:36:03.576349Z",
     "start_time": "2021-01-17T05:36:03.571359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(918, 55, 704)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T05:36:06.466873Z",
     "start_time": "2021-01-17T05:36:06.461884Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(918,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T05:22:45.172274Z",
     "start_time": "2021-01-17T05:22:45.154305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
       "       3., 3., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
       "       4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
       "       4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
       "       4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
       "       4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
       "       4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
       "       4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
       "       4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
       "       4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
       "       5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-17T05:56:29.454342Z",
     "start_time": "2021-01-17T05:36:47.854387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(734, 55, 704, 1)\n",
      "(734, 6)\n",
      "Epoch 1/35\n",
      "92/92 - 18s - loss: 2.1995 - accuracy: 0.1798 - val_loss: 1.7859 - val_accuracy: 0.1685\n",
      "Epoch 2/35\n",
      "92/92 - 18s - loss: 1.7335 - accuracy: 0.2766 - val_loss: 1.7366 - val_accuracy: 0.2609\n",
      "Epoch 3/35\n",
      "92/92 - 18s - loss: 1.4338 - accuracy: 0.4332 - val_loss: 1.7345 - val_accuracy: 0.2609\n",
      "Epoch 4/35\n",
      "92/92 - 18s - loss: 1.0557 - accuracy: 0.6117 - val_loss: 1.8415 - val_accuracy: 0.2935\n",
      "Epoch 5/35\n",
      "92/92 - 19s - loss: 0.6786 - accuracy: 0.7493 - val_loss: 2.2799 - val_accuracy: 0.2880\n",
      "Epoch 6/35\n",
      "92/92 - 17s - loss: 0.3409 - accuracy: 0.8856 - val_loss: 2.4520 - val_accuracy: 0.2826\n",
      "Epoch 7/35\n",
      "92/92 - 19s - loss: 0.1775 - accuracy: 0.9428 - val_loss: 3.0481 - val_accuracy: 0.2989\n",
      "Epoch 8/35\n",
      "92/92 - 19s - loss: 0.0953 - accuracy: 0.9714 - val_loss: 3.4261 - val_accuracy: 0.3261\n",
      "Epoch 9/35\n",
      "92/92 - 17s - loss: 0.0649 - accuracy: 0.9796 - val_loss: 3.5660 - val_accuracy: 0.2989\n",
      "Epoch 10/35\n",
      "92/92 - 19s - loss: 0.0528 - accuracy: 0.9850 - val_loss: 3.5743 - val_accuracy: 0.3315\n",
      "Epoch 11/35\n",
      "92/92 - 18s - loss: 0.0391 - accuracy: 0.9864 - val_loss: 3.7112 - val_accuracy: 0.2989\n",
      "Epoch 12/35\n",
      "92/92 - 18s - loss: 0.0210 - accuracy: 0.9959 - val_loss: 3.9642 - val_accuracy: 0.3152\n",
      "Epoch 13/35\n",
      "92/92 - 18s - loss: 0.0121 - accuracy: 0.9973 - val_loss: 4.2108 - val_accuracy: 0.3043\n",
      "1\n",
      "(734, 55, 704, 1)\n",
      "(734, 6)\n",
      "Epoch 1/35\n",
      "92/92 - 17s - loss: 2.2384 - accuracy: 0.2153 - val_loss: 1.7575 - val_accuracy: 0.2935\n",
      "Epoch 2/35\n",
      "92/92 - 17s - loss: 1.6322 - accuracy: 0.3488 - val_loss: 1.6550 - val_accuracy: 0.3098\n",
      "Epoch 3/35\n",
      "92/92 - 17s - loss: 1.2412 - accuracy: 0.5477 - val_loss: 1.6225 - val_accuracy: 0.3424\n",
      "Epoch 4/35\n",
      "92/92 - 17s - loss: 0.5553 - accuracy: 0.8392 - val_loss: 1.8059 - val_accuracy: 0.3098\n",
      "Epoch 5/35\n",
      "92/92 - 17s - loss: 0.1444 - accuracy: 0.9673 - val_loss: 2.1250 - val_accuracy: 0.3370\n",
      "Epoch 6/35\n",
      "92/92 - 22s - loss: 0.0365 - accuracy: 0.9932 - val_loss: 2.7409 - val_accuracy: 0.2717\n",
      "Epoch 7/35\n",
      "92/92 - 18s - loss: 0.0135 - accuracy: 1.0000 - val_loss: 2.7857 - val_accuracy: 0.3207\n",
      "Epoch 8/35\n",
      "92/92 - 18s - loss: 0.0184 - accuracy: 0.9973 - val_loss: 2.7347 - val_accuracy: 0.3207\n",
      "Epoch 9/35\n",
      "92/92 - 19s - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.8452 - val_accuracy: 0.3261\n",
      "Epoch 10/35\n",
      "92/92 - 18s - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.9777 - val_accuracy: 0.3315\n",
      "Epoch 11/35\n",
      "92/92 - 17s - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.0096 - val_accuracy: 0.3424\n",
      "Epoch 12/35\n",
      "92/92 - 18s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.0742 - val_accuracy: 0.3478\n",
      "Epoch 13/35\n",
      "92/92 - 18s - loss: 9.4943e-04 - accuracy: 1.0000 - val_loss: 3.1928 - val_accuracy: 0.3370\n",
      "2\n",
      "(734, 55, 704, 1)\n",
      "(734, 6)\n",
      "Epoch 1/35\n",
      "92/92 - 17s - loss: 2.3088 - accuracy: 0.1649 - val_loss: 1.7915 - val_accuracy: 0.1739\n",
      "Epoch 2/35\n",
      "92/92 - 16s - loss: 1.7893 - accuracy: 0.2003 - val_loss: 1.7910 - val_accuracy: 0.1413\n",
      "Epoch 3/35\n",
      "92/92 - 20s - loss: 1.7507 - accuracy: 0.2793 - val_loss: 1.7252 - val_accuracy: 0.3207\n",
      "Epoch 4/35\n",
      "92/92 - 20s - loss: 1.3793 - accuracy: 0.4864 - val_loss: 1.6568 - val_accuracy: 0.3587\n",
      "Epoch 5/35\n",
      "92/92 - 18s - loss: 0.6619 - accuracy: 0.7738 - val_loss: 1.9687 - val_accuracy: 0.3587\n",
      "Epoch 6/35\n",
      "92/92 - 17s - loss: 0.1543 - accuracy: 0.9564 - val_loss: 2.3945 - val_accuracy: 0.3043\n",
      "Epoch 7/35\n",
      "92/92 - 20s - loss: 0.0541 - accuracy: 0.9918 - val_loss: 3.0301 - val_accuracy: 0.3207\n",
      "Epoch 8/35\n",
      "92/92 - 19s - loss: 0.0233 - accuracy: 0.9986 - val_loss: 3.1247 - val_accuracy: 0.3207\n",
      "Epoch 9/35\n",
      "92/92 - 17s - loss: 0.0259 - accuracy: 0.9905 - val_loss: 3.7911 - val_accuracy: 0.2989\n",
      "Epoch 10/35\n",
      "92/92 - 20s - loss: 0.0252 - accuracy: 0.9959 - val_loss: 3.2775 - val_accuracy: 0.3261\n",
      "Epoch 11/35\n",
      "92/92 - 20s - loss: 0.0137 - accuracy: 0.9959 - val_loss: 3.4712 - val_accuracy: 0.3261\n",
      "Epoch 12/35\n",
      "92/92 - 19s - loss: 0.0062 - accuracy: 0.9986 - val_loss: 3.7716 - val_accuracy: 0.3370\n",
      "Epoch 13/35\n",
      "92/92 - 20s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 4.1156 - val_accuracy: 0.3315\n",
      "Epoch 14/35\n",
      "92/92 - 20s - loss: 0.0061 - accuracy: 0.9986 - val_loss: 4.1062 - val_accuracy: 0.3424\n",
      "3\n",
      "(735, 55, 704, 1)\n",
      "(735, 6)\n",
      "Epoch 1/35\n",
      "92/92 - 18s - loss: 2.3908 - accuracy: 0.1714 - val_loss: 1.7910 - val_accuracy: 0.1749\n",
      "Epoch 2/35\n",
      "92/92 - 18s - loss: 1.7775 - accuracy: 0.2163 - val_loss: 1.7257 - val_accuracy: 0.2787\n",
      "Epoch 3/35\n",
      "92/92 - 18s - loss: 1.6441 - accuracy: 0.3143 - val_loss: 1.6510 - val_accuracy: 0.3005\n",
      "Epoch 4/35\n",
      "92/92 - 18s - loss: 1.2763 - accuracy: 0.4844 - val_loss: 1.7799 - val_accuracy: 0.2896\n",
      "Epoch 5/35\n",
      "92/92 - 18s - loss: 0.8426 - accuracy: 0.6980 - val_loss: 2.0498 - val_accuracy: 0.2896\n",
      "Epoch 6/35\n",
      "92/92 - 18s - loss: 0.4319 - accuracy: 0.8490 - val_loss: 2.4555 - val_accuracy: 0.3333\n",
      "Epoch 7/35\n",
      "92/92 - 18s - loss: 0.1938 - accuracy: 0.9333 - val_loss: 2.8863 - val_accuracy: 0.2350\n",
      "Epoch 8/35\n",
      "92/92 - 18s - loss: 0.0985 - accuracy: 0.9728 - val_loss: 3.3401 - val_accuracy: 0.2896\n",
      "Epoch 9/35\n",
      "92/92 - 18s - loss: 0.0590 - accuracy: 0.9850 - val_loss: 3.6005 - val_accuracy: 0.2787\n",
      "Epoch 10/35\n",
      "92/92 - 18s - loss: 0.0527 - accuracy: 0.9864 - val_loss: 3.6671 - val_accuracy: 0.2623\n",
      "Epoch 11/35\n",
      "92/92 - 20s - loss: 0.0426 - accuracy: 0.9864 - val_loss: 3.7331 - val_accuracy: 0.3388\n",
      "Epoch 12/35\n",
      "92/92 - 17s - loss: 0.0335 - accuracy: 0.9918 - val_loss: 3.8358 - val_accuracy: 0.2896\n",
      "Epoch 13/35\n",
      "92/92 - 18s - loss: 0.0174 - accuracy: 0.9986 - val_loss: 4.0433 - val_accuracy: 0.3115\n",
      "4\n",
      "(735, 55, 704, 1)\n",
      "(735, 6)\n",
      "Epoch 1/35\n",
      "92/92 - 16s - loss: 2.3526 - accuracy: 0.1878 - val_loss: 1.7865 - val_accuracy: 0.1803\n",
      "Epoch 2/35\n",
      "92/92 - 17s - loss: 1.7145 - accuracy: 0.2789 - val_loss: 1.6780 - val_accuracy: 0.3005\n",
      "Epoch 3/35\n",
      "92/92 - 16s - loss: 1.4351 - accuracy: 0.4490 - val_loss: 1.7494 - val_accuracy: 0.2240\n",
      "Epoch 4/35\n",
      "92/92 - 16s - loss: 1.1118 - accuracy: 0.5878 - val_loss: 1.9995 - val_accuracy: 0.2951\n",
      "Epoch 5/35\n",
      "92/92 - 16s - loss: 0.7579 - accuracy: 0.7333 - val_loss: 1.9636 - val_accuracy: 0.3115\n",
      "Epoch 6/35\n",
      "92/92 - 16s - loss: 0.3147 - accuracy: 0.9102 - val_loss: 2.5374 - val_accuracy: 0.2678\n",
      "Epoch 7/35\n",
      "92/92 - 16s - loss: 0.1327 - accuracy: 0.9619 - val_loss: 3.1940 - val_accuracy: 0.2896\n",
      "Epoch 8/35\n",
      "92/92 - 16s - loss: 0.0516 - accuracy: 0.9905 - val_loss: 3.3776 - val_accuracy: 0.2787\n",
      "Epoch 9/35\n",
      "92/92 - 16s - loss: 0.0463 - accuracy: 0.9878 - val_loss: 3.2865 - val_accuracy: 0.2787\n",
      "Epoch 10/35\n",
      "92/92 - 16s - loss: 0.0190 - accuracy: 0.9959 - val_loss: 3.5011 - val_accuracy: 0.2842\n",
      "Epoch 11/35\n",
      "92/92 - 16s - loss: 0.0249 - accuracy: 0.9918 - val_loss: 3.4185 - val_accuracy: 0.2514\n",
      "Epoch 12/35\n",
      "92/92 - 16s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 3.6776 - val_accuracy: 0.2951\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "# 5折交叉\n",
    "\n",
    "test_pred = np.zeros((228, 6))\n",
    "for idx, (tr_idx, val_idx) in enumerate(skf.split(X, Y)):\n",
    "    print(idx)\n",
    "\n",
    "    epochs = 35 # 训练迭代次数\n",
    "    batch_size = 8 \n",
    "    verbose = 2 \n",
    "\n",
    "    X_train, X_test = X[tr_idx], X[val_idx]\n",
    "    y_train, y_test = Y[tr_idx], Y[val_idx]\n",
    "    \n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1) \n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "    print(X_train.shape)\n",
    "    \n",
    "    y_train_hot = to_categorical(y_train) \n",
    "    print(y_train_hot.shape)\n",
    "    y_test_hot = to_categorical(y_test)\n",
    "    \n",
    "    model = get_model()\n",
    "    # 初始化模型\n",
    "    \n",
    "    my_callbacks = [\n",
    "        keras.callbacks.EarlyStopping(patience=10), # 早停：patience: 早停轮数\n",
    "#         keras.callbacks.ModelCheckpoint(filepath='model-{0}.h5'.format(idx), save_best_only=True),\n",
    "        # 在每个训练期之后保存模型。\n",
    "        # filepath: 保存模型的路径。\n",
    "    ]\n",
    "\n",
    "    model.fit(X_train, y_train_hot, \n",
    "              batch_size=batch_size,  \n",
    "              epochs=epochs,  \n",
    "              verbose=verbose,  \n",
    "              validation_data=(X_test, y_test_hot),  # 评估损失数据集\n",
    "              callbacks=my_callbacks # 回调函数\n",
    "             )\n",
    "#     model.load_weights('model-{0}.h5'.format(idx))\n",
    "    # 加载模型权重\n",
    "    \n",
    "    X_test = np.load('test.npy') \n",
    "    test_pred += model.predict(X_test.reshape(228, 55, 704, 1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = np.zeros((228, 6))\n",
    "for path in ['model-0.h5', 'model-2.h5', 'model-6.h5'][:1]:\n",
    "    model.load_weights(path) # 加载模型权重\n",
    "    \n",
    "    X_test = np.load('test.npy') / 255.0\n",
    "    test_pred += model.predict(X_test.reshape(228, 20, 400, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 投票"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['id'] = [wavfile for wavfile in os.listdir(DATA_TEST_PATH)]\n",
    "df['label'] = [['hug', 'sleepy', 'uncomfortable', 'hungry', 'awake', 'diaper'][x] for x in test_pred.argmax(1)]\n",
    "# x（索引）的取值：argmax(1)：从一维上进行比较，相较于0维，小一个维度 的索引\n",
    "# 可能性最高的为类别\n",
    "df.to_csv('.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "296.141px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
